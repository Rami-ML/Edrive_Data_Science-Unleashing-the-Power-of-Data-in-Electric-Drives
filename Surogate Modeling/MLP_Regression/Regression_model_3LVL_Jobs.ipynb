{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FdFUI6Ow3cXV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.parallel\n",
    "import pandas as pd\n",
    "#from ray import tune\n",
    "#from ray.tune import grid_search, uniform\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import scipy.io\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "b6qrXTf73fG3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3201204, 31)\n",
      "(3201204, 25)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import io\n",
    "import scipy.io\n",
    "\n",
    "# Specify the S3 bucket and file path\n",
    "bucket_name = 'sagemaker-studio-12bcc0mjktib'\n",
    "file_key = '2LVSI_scaled_extra.mat'\n",
    "\n",
    "# Create a Boto3 S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Download the file from S3\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "file_content = response['Body'].read()\n",
    "\n",
    "# Load the .mat file using scipy.io\n",
    "mat_data = scipy.io.loadmat(io.BytesIO(file_content))\n",
    "\n",
    "# Continue with the rest of your code\n",
    "input_scaled = mat_data.get('input_scaled')\n",
    "output_scaled = mat_data.get('output_scaled')\n",
    "\n",
    "# Split the dataset into input and output subsets\n",
    "input_subset = input_scaled[:, :-6]\n",
    "output_subset = output_scaled[:, :-6]\n",
    "\n",
    "# Verify the shape of the resulting subsets\n",
    "print(input_subset.shape)\n",
    "print(output_subset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "w3Rj_OsqvpPj"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self, input_size, output_size, dropout =  0.005 , num_layers = 3, num_neurons =2048):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.bn_layers = nn.ModuleList()\n",
    "        self.activation_fn = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "          if i == 0:\n",
    "            self.layers.append(nn.Linear(input_size, num_neurons))\n",
    "            self.bn_layers.append(nn.BatchNorm1d(num_neurons))\n",
    "          else:\n",
    "            self.layers.append(nn.Linear(num_neurons // (2**(i-1)), num_neurons // (2**i)))\n",
    "            self.bn_layers.append(nn.BatchNorm1d(num_neurons // (2**i)))\n",
    "\n",
    "        # Try Relu also here after going through hyperparamter tuning\n",
    "        self.output_layer = nn.Linear(num_neurons // (2**(num_layers-1)), output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x):\n",
    "      for i in range(self.num_layers):\n",
    "        x = self.layers[i](x)\n",
    "        x = self.bn_layers[i](x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation_fn(x)\n",
    "\n",
    "      x = self.output_layer(x)\n",
    "      x = self.sigmoid(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eazd6MWe346X",
    "outputId": "2ac859f9-9c87-4459-8dd5-8d667b69065b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "input_data = torch.Tensor(input_subset)\n",
    "output_data = torch.Tensor(output_subset)\n",
    "#print(input_data)\n",
    "\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "#test_size = 0.2 ist 80% Training set\n",
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "    input_data, output_data, test_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "#test_size hier auf 0.5 heißt die übrigen 20% nochmal in 10% für val und 10% für test\n",
    "val_data, test_data, val_target, test_target = train_test_split(\n",
    "    test_data, test_target, test_size=0.5, random_state=42\n",
    ")\n",
    "#data = pd.DataFrame(train_data.numpy())\n",
    "#print(len(data.iloc[:,7]))\n",
    "#unique_values = data.iloc[:,7].unique()\n",
    "#print(len(unique_values))\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(train_data, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataset = TensorDataset(val_data, val_target)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataset = TensorDataset(test_data, test_target)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fS49tFg537xf",
    "outputId": "cb823547-8728-4484-c8d5-a1615820bd98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3201204\n",
      "Dropout value: 0002\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions of your input, hidden, and output layers\n",
    "input_size = input_data.shape[1]\n",
    "output_size = output_data.shape[1]\n",
    "print(input_data.shape[0])\n",
    "# Create an instance of the MLP model\n",
    "model = MLP(input_size, output_size).to(device)\n",
    "#model = MLP1(input_size, output_size).to(device)\n",
    "\n",
    "#Define inital data\n",
    "test_accuracies = []\n",
    "best_test_accuracy = 0.0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "#get_dropout = MLP(input_size, output_size).dropout\n",
    "get_dropout = MLP(input_size, output_size).dropout\n",
    "# Access the dropout probability 'p'\n",
    "dropout_probability = get_dropout.p\n",
    "\n",
    "# Print the dropout probability\n",
    "print(dropout_probability)\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "lr = 0.006\n",
    "string_loss = \"MSE\"\n",
    "string_optimizer = \"ADAM\"\n",
    "num_epochs = 1000\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOk5T8dG3-YM",
    "outputId": "b7327d1c-8054-420e-a700-c76aa31541ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.000372, Val Loss: 0.000058\n",
      "Epoch [2/15], Train Loss: 0.000096, Val Loss: 0.000035\n",
      "Epoch [3/15], Train Loss: 0.000067, Val Loss: 0.000029\n",
      "Epoch [4/15], Train Loss: 0.000055, Val Loss: 0.000028\n",
      "Epoch [5/15], Train Loss: 0.000047, Val Loss: 0.000023\n",
      "Epoch [6/15], Train Loss: 0.000041, Val Loss: 0.000015\n",
      "Epoch [7/15], Train Loss: 0.000038, Val Loss: 0.000016\n",
      "Epoch [8/15], Train Loss: 0.000035, Val Loss: 0.000017\n",
      "Epoch [9/15], Train Loss: 0.000031, Val Loss: 0.000013\n",
      "Epoch [10/15], Train Loss: 0.000029, Val Loss: 0.000016\n",
      "Epoch [11/15], Train Loss: 0.000027, Val Loss: 0.000016\n",
      "Epoch [12/15], Train Loss: 0.000026, Val Loss: 0.000016\n",
      "Epoch [13/15], Train Loss: 0.000024, Val Loss: 0.000009\n",
      "Epoch [14/15], Train Loss: 0.000022, Val Loss: 0.000010\n",
      "Epoch [15/15], Train Loss: 0.000021, Val Loss: 0.000010\n"
     ]
    }
   ],
   "source": [
    "#MSE Loss function\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.RMSprop(model.parameters(), lr)\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "#optimizer = optim.Adamax(model.parameters(), lr)\n",
    "#optimizer =  optim.SGD(model.parameters(), lr)\n",
    "\n",
    "#Take care of negative values when using this loss function!\n",
    "def msle_loss(output, target):\n",
    "    log_output = torch.log(output + 1)\n",
    "    log_target = torch.log(target + 1)\n",
    "    mse_loss = criterion(log_output, log_target)\n",
    "    return mse_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        #loss =  msle_loss(outputs, labels)\n",
    "        loss =  criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            #loss =  msle_loss(outputs, labels)\n",
    "            loss =  criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    # Check if the current validation loss is better than the previous best\n",
    "    if val_loss < best_val_loss:\n",
    "        # Update the best validation loss\n",
    "        best_val_loss = val_loss\n",
    "        # Save the model's state\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "# Load the best model state for evaluation\n",
    "model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeQZr8Ik4A6g",
    "outputId": "878acb84-28ee-4fe7-ec08-78e7a9e27776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.0032\n"
     ]
    }
   ],
   "source": [
    "#RMSE Error metric\n",
    "#RMSE Error shows the biggest difference of predicted value to original value\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "rmse = test_loss ** 0.5  # Calculate the square root of the MSE\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "#print(f\"Test MSE: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LA2EekR4Dnp",
    "outputId": "83f576b3-fc93-4bb2-98fb-832d8e263e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.0014\n"
     ]
    }
   ],
   "source": [
    "#MAE (Mean Absolute Error) Error metric\n",
    "#Shows you the average difference between the predicted values and the original values\n",
    "model.eval()\n",
    "test_mae = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        mae = torch.mean(torch.abs(outputs - labels))\n",
    "        test_mae += mae.item()\n",
    "\n",
    "test_mae /= len(test_loader)\n",
    "print(f\"Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzjyiwjY4Fcw",
    "outputId": "96eee734-cf49-4c9c-ddfc-6eae8c8ff967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.997369\n",
      "Adjusted R^2 Score: 0.997368\n",
      "best_model_r_square_0.99737_epoch_15_loss_MSE_optimizer_ADAM_lr_0.0004_dropout_0002_data_size_3201204.pt\n"
     ]
    }
   ],
   "source": [
    "#R2-Score metric\n",
    "#If R-square equals 1, it means that the model perfectly fits\n",
    "#the data and there is no difference between the predicted value and actual value!\n",
    "model.eval()\n",
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        predictions.append(outputs.cpu().numpy())\n",
    "        targets.append(labels.cpu().numpy())\n",
    "\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "targets = np.concatenate(targets, axis=0)\n",
    "\n",
    "#Adjusted R2-Score\n",
    "def adjusted_r2_score(r2, n_samples, n_features):\n",
    "    adj_r2 = 1 - (1 - r2) * (n_samples - 1) / (n_samples - n_features - 1)\n",
    "    return adj_r2\n",
    "\n",
    "# Get the number of samples and features\n",
    "n_samples = targets.shape[0]\n",
    "n_features = inputs.shape[1]  # Replace 'inputs' with the appropriate variable containing your input data\n",
    "\n",
    "# Calculate R2 score\n",
    "r2 = r2_score(targets, predictions)\n",
    "\n",
    "# Calculate Adjusted R2 score\n",
    "adj_r2 = adjusted_r2_score(r2, n_samples, n_features)\n",
    "\n",
    "# Print both R2 and Adjusted R2 scores\n",
    "print(f\"R^2 Score: {r2:.6f}\")\n",
    "print(f\"Adjusted R^2 Score: {adj_r2:.6f}\")\n",
    "\n",
    "# Define the filename for saving the model\n",
    "string = \"best_model_r_square_{0}_epoch_{1}_loss_{2}_optimizer_{3}_lr_{4}_dropout_{5}_data_size_{6}.pt\".format(\n",
    "round(r2,5), num_epochs, string_loss, string_optimizer, lr, dropout_probability, input_data.shape[0])\n",
    "print(string)\n",
    "# Save the model in the current working directory\n",
    "# Specify the S3 bucket name\n",
    "bucket_name = 'sagemaker-studio-12bcc0mjktib'\n",
    "\n",
    "# Create a Boto3 S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "torch.save(model.state_dict(), string)\n",
    "#s3_client.upload_file(string, bucket_name, os.path.basename(string))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
